{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Low-Bit-Quantization-Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtViN35Kb-kG"
      },
      "source": [
        "# Imports \n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import time\n",
        "import sys\n",
        "# for importing quantization specific libs\n",
        "import torch.quantization\n",
        "import torchvision.models.quantization as qmodels"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ft24sTMHc9xA"
      },
      "source": [
        "# in this tutorial, we will use resnet18\n",
        "# will train for cifar10 data\n",
        "# test with fp32 weights\n",
        "# then compress\n",
        "# and test with int8 weights\n",
        "model = qmodels.resnet18(pretrained=True)\n",
        "feats = model.fc.in_features\n",
        "model.fc = nn.Linear(feats, 10)\n",
        "model = model.cuda()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-fTGdeyc0WB",
        "outputId": "d6320dc6-ab02-4ed8-ced9-7e9266c901b6"
      },
      "source": [
        "def print_size_of_model(model):\n",
        "    torch.save(model.state_dict(), \"temp.p\")\n",
        "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
        "    os.remove('temp.p')\n",
        "\n",
        "print_size_of_model(model)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size (MB): 44.808761\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVk6xmw8miu3",
        "outputId": "55674378-0cd7-435a-e5bc-3652c770fb8a"
      },
      "source": [
        "# define datasets: cifar10\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNPybDeNmygl"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PF33XZmcneVn",
        "outputId": "ef154aa2-1e7b-48e5-f643-c07a551d5d2c"
      },
      "source": [
        "model.train()\n",
        "# training for only five epoch for faster demo..\n",
        "# train for longer epochs to get better acc.\n",
        "for epoch in range(5):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "            torch.save(model.state_dict(), './model.pth')\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 2.485\n",
            "[1,  4000] loss: 2.407\n",
            "[1,  6000] loss: 2.368\n",
            "[1,  8000] loss: 2.308\n",
            "[1, 10000] loss: 2.274\n",
            "[1, 12000] loss: 2.173\n",
            "[2,  2000] loss: 2.086\n",
            "[2,  4000] loss: 2.062\n",
            "[2,  6000] loss: 2.007\n",
            "[2,  8000] loss: 2.006\n",
            "[2, 10000] loss: 1.924\n",
            "[2, 12000] loss: 1.940\n",
            "[3,  2000] loss: 1.864\n",
            "[3,  4000] loss: 1.828\n",
            "[3,  6000] loss: 1.770\n",
            "[3,  8000] loss: 1.739\n",
            "[3, 10000] loss: 1.733\n",
            "[3, 12000] loss: 1.682\n",
            "[4,  2000] loss: 1.637\n",
            "[4,  4000] loss: 1.596\n",
            "[4,  6000] loss: 1.565\n",
            "[4,  8000] loss: 1.598\n",
            "[4, 10000] loss: 1.572\n",
            "[4, 12000] loss: 1.584\n",
            "[5,  2000] loss: 1.534\n",
            "[5,  4000] loss: 1.515\n",
            "[5,  6000] loss: 1.507\n",
            "[5,  8000] loss: 1.500\n",
            "[5, 10000] loss: 1.506\n",
            "[5, 12000] loss: 1.472\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLjQ0oKboX5O",
        "outputId": "3cd30f6c-e29d-4ba7-c737-07cbb37e11ec"
      },
      "source": [
        "model.load_state_dict(torch.load('./model.pth'))\n",
        "model.eval()\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        images, labels = images.cuda(), labels.cuda()\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 50 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NwC2ydHuCx6",
        "outputId": "efdd8fe3-ca4c-4ccd-8fe9-1b6fdfbb8ed6"
      },
      "source": [
        "# quantization part\n",
        "model.load_state_dict(torch.load('./model.pth'))\n",
        "model.eval()\n",
        "model.fuse_model()\n",
        "model.cpu()\n",
        "\n",
        "# Specify quantization configuration\n",
        "# Start with simple min/max range estimation and per-tensor quantization of weights\n",
        "model.qconfig = torch.quantization.default_qconfig\n",
        "print(model.qconfig)\n",
        "torch.quantization.prepare(model, inplace=True)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "QConfig(activation=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, reduce_range=True), weight=functools.partial(<class 'torch.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/quantization/observer.py:123: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
            "  reduce_range will be deprecated in a future release of PyTorch.\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "QuantizableResNet(\n",
              "  (conv1): ConvReLU2d(\n",
              "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
              "    (1): ReLU()\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (bn1): Identity()\n",
              "  (relu): Identity()\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): QuantizableBasicBlock(\n",
              "      (conv1): ConvReLU2d(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU()\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "      (bn1): Identity()\n",
              "      (relu): Identity()\n",
              "      (conv2): Conv2d(\n",
              "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "      (bn2): Identity()\n",
              "      (add_relu): FloatFunctional(\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "    )\n",
              "    (1): QuantizableBasicBlock(\n",
              "      (conv1): ConvReLU2d(\n",
              "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU()\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "      (bn1): Identity()\n",
              "      (relu): Identity()\n",
              "      (conv2): Conv2d(\n",
              "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "      (bn2): Identity()\n",
              "      (add_relu): FloatFunctional(\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): QuantizableBasicBlock(\n",
              "      (conv1): ConvReLU2d(\n",
              "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        (1): ReLU()\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "      (bn1): Identity()\n",
              "      (relu): Identity()\n",
              "      (conv2): Conv2d(\n",
              "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "      (bn2): Identity()\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(\n",
              "          64, 128, kernel_size=(1, 1), stride=(2, 2)\n",
              "          (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "        (1): Identity()\n",
              "      )\n",
              "      (add_relu): FloatFunctional(\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "    )\n",
              "    (1): QuantizableBasicBlock(\n",
              "      (conv1): ConvReLU2d(\n",
              "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU()\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "      (bn1): Identity()\n",
              "      (relu): Identity()\n",
              "      (conv2): Conv2d(\n",
              "        128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "      (bn2): Identity()\n",
              "      (add_relu): FloatFunctional(\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): QuantizableBasicBlock(\n",
              "      (conv1): ConvReLU2d(\n",
              "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        (1): ReLU()\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "      (bn1): Identity()\n",
              "      (relu): Identity()\n",
              "      (conv2): Conv2d(\n",
              "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "      (bn2): Identity()\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(\n",
              "          128, 256, kernel_size=(1, 1), stride=(2, 2)\n",
              "          (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "        (1): Identity()\n",
              "      )\n",
              "      (add_relu): FloatFunctional(\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "    )\n",
              "    (1): QuantizableBasicBlock(\n",
              "      (conv1): ConvReLU2d(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU()\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "      (bn1): Identity()\n",
              "      (relu): Identity()\n",
              "      (conv2): Conv2d(\n",
              "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "      (bn2): Identity()\n",
              "      (add_relu): FloatFunctional(\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): QuantizableBasicBlock(\n",
              "      (conv1): ConvReLU2d(\n",
              "        (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        (1): ReLU()\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "      (bn1): Identity()\n",
              "      (relu): Identity()\n",
              "      (conv2): Conv2d(\n",
              "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "      (bn2): Identity()\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(\n",
              "          256, 512, kernel_size=(1, 1), stride=(2, 2)\n",
              "          (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "        )\n",
              "        (1): Identity()\n",
              "      )\n",
              "      (add_relu): FloatFunctional(\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "    )\n",
              "    (1): QuantizableBasicBlock(\n",
              "      (conv1): ConvReLU2d(\n",
              "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): ReLU()\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "      (bn1): Identity()\n",
              "      (relu): Identity()\n",
              "      (conv2): Conv2d(\n",
              "        512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "      (bn2): Identity()\n",
              "      (add_relu): FloatFunctional(\n",
              "        (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(\n",
              "    in_features=512, out_features=10, bias=True\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (quant): QuantStub(\n",
              "    (activation_post_process): MinMaxObserver(min_val=inf, max_val=-inf)\n",
              "  )\n",
              "  (dequant): DeQuantStub()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KG-nePDVvHS_"
      },
      "source": [
        "def calibrate(model, data_loader, neval_batches):\n",
        "    cnt = 0\n",
        "    with torch.no_grad():\n",
        "        for image, target in data_loader:\n",
        "            output = model(image)\n",
        "            cnt += 1 \n",
        "            if cnt >= neval_batches:\n",
        "                 return None\n",
        "    return None"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrRMdFknvBwI",
        "outputId": "1db9c66b-fdc7-4400-e139-5d2b384febec"
      },
      "source": [
        "# Calibrate with the training set using only 32 images\n",
        "calibrate(model, trainloader, neval_batches=32)\n",
        "print('Post Training Quantization: Calibration done')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Post Training Quantization: Calibration done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNTVVJ3Qvqfp",
        "outputId": "53cf6460-5daf-4c4c-c554-b9f1f1e58e58"
      },
      "source": [
        "# Convert to quantized model\n",
        "torch.quantization.convert(model, inplace=True)\n",
        "print('Post Training Quantization: Convert done')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Post Training Quantization: Convert done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WNDR8k0vxMJ",
        "outputId": "e1bf184a-6fba-498e-c4db-cf30d9b8b097"
      },
      "source": [
        "print(\"Size of model after quantization\")\n",
        "print_size_of_model(model)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of model after quantization\n",
            "Size (MB): 11.226885\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ogwv1jmTv6an",
        "outputId": "cf82eb61-32c5-4e9a-81d2-3878cc14c8de"
      },
      "source": [
        "# testing the int8 model\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        # images, labels = images.cuda(), labels.cuda()\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the quantized network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the quantized network on the 10000 test images: 45 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}